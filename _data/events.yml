# 
# title:
# tag: Entrepreneurship/Seminar/Workshop/Course
# who:
# date:
# time:
# description:
# wholink:  speaker URL
# link: title URL
# video: link to youtube recording
# slides: link to slides
# 
#

- title: 'AI for IT Automation: Benchmarking and Agent Development Research @ IBM'
  tag: Seminar
  date: '2025-12-16'
  who: Saurabh Jha, Yu Deng, Daby Sow, Ruchi Mahindru
  where: CSB 453
  time: 12PM
  description: >
    IT outages remain frequent and expensive and stem from diverse causes spanning
    network failures, third-party/cloud dependencies, configuration drift, and software
    bugs—making automation uniquely challenging in the IT domain. This talk introduces
    ITBench, an open and extensible benchmark of real-world IT automation scenarios
    with a rigorous evaluation framework, designed to assess and improve LLM/agent
    performance across SRE, FinOps, and security tasks—and to enable gym-style RL
    fine-tuning.  We describe our broader benchmarking effort: how we operationalize
    scenarios + environments, standardize evaluation, and build a community around
    open-source agents and tooling to make results reproducible and comparable.
    We also share our Kaggle leaderboards release (ITBench Snapshots)—a diagnosis-focused
    subset intended to catalyze open evaluation and rapid iteration. The leaderboards
    highlight a key reality: even strong models still struggle with end-to-end reliability,
    and baseline performance remains far from "production-ready." Finally, we outline
    how we're pushing beyond today's architectures—showing progress toward 80%+
    accuracy in targeted settings—and why treating ITBench as a gym-like environment
    is a practical path to train RL-driven agents that achieve higher accuracy at
    lower cost.

- title: 'Validation Techniques for Offensive Security Agents'
  tag: Seminar
  date: '2025-12-09'
  who: Brendan Dolan-Gavitt
  where: CSB 453
  time: 12PM
  wholink: https://www.linkedin.com/in/brendan-dolan-gavitt-3b68154/
  description: >
    Large language models are increasingly helping to automate vulnerability
    discovery and exploit development in real-world software. However, naïvely
    asking LLMs to identify vulnerabilities leads to a deluge of false positives
    that can drown out real findings. In this talk, we will present techniques
    that enable AI agents to find vulnerabilities at scale, fully autonomously
    and with minimal false positives. The key to our approach is developing
    robust exploit validators that can conclusively determine whether an exploit
    claimed by the agent is real, allowing the agent to make arbitrarily many
    attempts without  the amount of human effort needed to review the results.
    Using these techniques, we were able to test thousands of web apps found on
    Docker Hub, identifying over 200 zero days and obtaining multiple CVEs, and
    identify vulnerabilities in black-box bug bounty targets from HackerOne,
    identifying more than 1000 vulnerabilities and reaching the #1 rank in the
    US on the HackerOne leaderboard.
  bio: >
    Brendan Dolan-Gavitt is an AI researcher at XBOW, where he helps build
    agents to identify critical vulnerabilities in software before they can be
    exploited by attackers (or attackers' agents!). Prior to joining XBOW, he
    was an associate professor at NYU Tandon, researching software security and
    machine learning.

- title: 'Building Foundation Models at Scale: System Experiences and Challenges'
  tag: Seminar
  date: '2025-11-21'
  who: Jingren Zhou
  where: Davis Auditorium
  time: 11AM
  wholink: https://www.cs.columbia.edu/~jrzhou/
  description: >
    The rapid evolution of AI has led to the emergence of massive and complex foundation models that
    require enormous computational resources, making efficient training and inference systems
    essential. Training such models requires large-scale distributed computation, effective overlap
    of computation and communication, sophisticated parallelization strategies, and robust fault-
    tolerant mechanisms. Inference systems, on the other hand, must support diverse workloads with
    varying service-level agreements (SLAs), rapidly integrate engineering optimizations, and
    carefully balance trade-offs among throughput, latency, cost, and availability, particularly in
    distributed environments. In this talk, I will discuss the major systems challenges in building
    large-scale foundation models, focusing on our experiences developing Qwen (large language
    models) and Wan (video generative models). I will also present ongoing research and system
    designs that enhance the efficiency of training and inference at scale, enabling more effective
    management of complex AI workloads in cloud environments.
  bio: >
    Jingren Zhou '01SEAS, '04SEAS is the Chief Technology Officer at Alibaba Cloud, where he drives
    technology innovation and product development across a wide range of cloud computing services.
    He also leads the development of AI foundation models, such as Qwen and Wan models, and their
    applications in diverse business applications within Alibaba Cloud. Prior to this role, he
    played a key role in building Alibaba's cloud-scale distributed data analytics platform and
    developing advanced techniques for personalized search, product recommendation, and advertising
    on Alibaba's e-commerce platform. Before joining Alibaba, he was a veteran at Microsoft,
    focusing on big data and database research and development. His research interests include
    cloud computing, distributed systems, databases, and large-scale machine learning. He has served
    as PC co-chair and core committee member for many academic conferences and technical forums. He
    received his PhD in Computer Science from Columbia University. He is a Fellow of ACM and IEEE.

- title: 'Enterprise App Platform Powered by Data and AI'
  tag: Seminar
  date: '2025-11-18'
  who: Justin DeBrabant
  where: CSB 453
  time: 12PM
  description: >
    Modern enterprises increasingly rely on the ability to rapidly iterate and deploy custom
    applications that tap into their core data assets. However, the transition from a "vibe coding"
    prototype to a production-ready application remains a significant hurdle due to the complexities
    of infrastructure management, security, and data governance. In this talk, Justin DeBrabant
    will be discussing how Databricks Apps addresses this "last-mile" challenge by providing
    a managed, serverless framework that allows developers to build and host applications directly
    alongside their data. He will break down the operational friction caused by moving data to
    external runtimes and demonstrate how integrating identity and governance into a single
    platform accelerates the delivery of interactive data-intelligence tools.
  bio: >
    Justin DeBrabant is the the Director of Product Management at Databricks, where he leads
    the initiative to enable developers to build data and AI applications directly on the
    Lakehouse platform. He previously served as the Chief Product Officer at ActionIQ and
    worked on the Big Data Platform at Two Sigma. He has also served as an Adjunct Professor at
    the University of Massachusetts Dartmouth. He holds a Ph.D. in Computer Science from Brown
    University, where his research focused on main-memory database architectures and "anti-caching"
    techniques for high-performance transaction processing.


- title: '2025 Undergraduate Computer and Data Science Research fair'
  tag: Workshop
  date: '2025-11-06'
  time: 5PM
  link: https://datascience.columbia.edu/events/undergraduate-research-fair-2025/
  description: >
    The UCDS research fair celebrates the leading undergraduate research across 
    Columbia University's many schools as well as Barnard College.  This is co-organized with 
    Columbia's [Data Science Institute](https://datascience.columbia.edu/), and check 
    [more details here](https://datascience.columbia.edu/events/undergraduate-research-fair-2025/)!

- title: 'Disaggregated LLM Inference: Past, Present, and Future'
  tag: Seminar
  date: '2025-10-14'
  who: Junda Chen
  where: CSB 453
  time: 12PM
  wholink: https://gindachen.github.io/
  description: >
    Large language model (LLM) serving faces a fundamental challenge: the prefill 
    phase is compute-bound while the decode phase is memory-bound. Existing serving 
    systems co-locate these two phases and batch their computation across users 
    and requests, a strategy that not only introduces strong prefill–decode 
    interference but also couples resource allocation and parallelism choices across both phases.
    We introduce DistServe, a low-latency serving engine that assigns prefill and 
    decode computation to different GPUs, thereby eliminating interference between 
    the two. DistServe co-optimizes resource allocation and parallelism strategies 
    tailored for each phase, while placing them across the cluster to account for 
    bandwidth constraints and minimize the communication overhead introduced by 
    disaggregation. As a result, DistServe substantially improves serving performance, 
    measured as the maximum request rate that can be sustained under strict time-to-first-token (TTFT) 
    and time-per-output-token (TPOT) constraints.
    Since DistServe, disaggregation has moved into the spotlight of LLM inference, 
    with many companies and open-source projects adopting or extending this paradigm in practice. 
    We will also highlight related academic and open-source work that has emerged around 
    disaggregated inference, and reflect on the open challenges faced today as well 
    as the opportunities that lie ahead.
  bio: > 
    Junda Chen is a third-year Ph.D. student in Computer Science at the 
    University of California, San Diego. His research focuses on large-scale 
    LLM systems, with an emphasis on efficient inference and training of large 
    language models. He is an author of DistServe, a disaggregated inference 
    system adopted by major industry partners (including NVIDIA Dynamo, llm-d, etc.). 
    His broader work spans GPU scheduling, distributed inference frameworks, and 
    the design of next-generation serving systems for foundation models.


- title: 'Keep Computing Systems Safe under Disruptive Agents'
  tag: Seminar
  date: '2025-10-07'
  who: Tianyin Xu
  where: CSB 453
  time: 12:30PM
  wholink : https://tianyin.github.io/
  description: >
    The brains of computing systems today have increasingly been realized by 
    generative AI such as Large Language Models (LLMs) together with agentic 
    technologies. While the AI approaches are arguably more creative and cheaper 
    to develop, their safety becomes a fundamental challenge. Instead of using 
    another LLM as a judge or waiting for a provably trustworthy model to exist, 
    we may want to figure out how to build seatbelts and airbags for computing 
    systems driven by LLMs/agents. In this talk, I will share our preliminary 
    experience of developing a site reliability engineering (SRE) agent which 
    attempts to autonomously mitigate production system failures. I would also 
    discuss the potential of advanced system intelligence – AI that can 
    understand "systems" beyond code and reason about their safety properties.  
  bio: > 
    Tianyin Xu is an Associate Professor of Computer Science at the University 
    of Illinois Urbana-Champaign (UIUC). His research focuses on building reliable 
    computer systems that empower next-generation computing. He has been on the 
    UIUC List of Teachers Ranked as Excellent for nine times. His work received 
    two OSDI Jay Lepreau Best Paper Awards, two ASPLOS Best Paper Awards, two 
    SIGSOFT Distinguished Paper Awards, a Gilles Muller Best Artifact Award, a 
    CACM Research Highlight, and an ICML Spotlight. He is also a recipient of 
    the C.W. Gear Outstanding Junior Faculty Award, a Dean's Award for Excellence 
    in Research, an Intel Rising Star Faculty Award, and a Facebook Distributed 
    Systems Research Award.

- title: 'Reality Checks'
  tag: Seminar
  date: '2025-09-30'
  who: Kyunghyun Cho
  where: CSB 453
  time: 12PM
  wholink: https://kyunghyuncho.me/
  description: >
    Despite its amazing success, leaderboard chasing has become something researchers dread and mock.
    When implemented properly and executed faithfully, leaderboard chasing can lead to both faster
    and easily reproducible progress in science, as evident from the amazing progress we have seen
    with machine learning, or more broadly artificial intelligence, in recent decades. It does not
    however mean that it is easy to implement and execute leaderboard chasing properly. In this talk,
    I will go over four case studies demonstrating the issues that ultimately prevent leaderboard
    chasing from a valid scientific approach. The first case study is on the lack of proper
    hyperparameter tuning in continual learning, the second on the lack of consensus on evaluation
    metrics in machine unlearning, the third on the challenges of properly evaluating the evaluation
    metrics in free-form text generation, and the final one on wishful thinking. By going over these
    cases, I hope we can collectively acknowledge some of our own fallacies, think of underlying
    causes behind these fallacies and come up with better ways to approach artificial intelligence research.  
  bio: > 
    Kyunghyun Cho is a professor of computer science and data science at New York University and an
    executive director of frontier research at the Prescient Design team within Genentech Research
    & Early Development (gRED). He became the Glen de Vries Professor of Health Statistics in 2025.
    He is also a CIFAR Fellow of Learning in Machines & Brains and an Associate Member of the
    National Academy of Engineering of Korea. He served as a (co-)Program Chair of ICLR 2020,
    NeurIPS 2022 and ICML 2022. He was one of the three founding Editors-in-Chief of the
    Transactions on Machine Learning Research (TMLR) until 2024. He was a research scientist at
    Facebook AI Research from June 2017 to May 2020 and a postdoctoral fellow at University of
    Montreal until Summer 2015 under the supervision of Prof. Yoshua Bengio, after receiving MSc
    and PhD degrees from Aalto University April 2011 and April 2014, respectively, under the
    supervision of Prof. Juha Karhunen, Dr. Tapani Raiko and Dr. Alexander Ilin. He received
    the Samsung Ho-Am Prize in Engineering in 2021. He tries his best to find a balance among
    machine learning, natural language processing, and life, but almost always fails to do so.

- title: 'Simulation Environments for testing and training task-focused AI agents'
  tag: Seminar
  who: Mehdi Jamei
  wholink: https://www.linkedin.com/in/mehdijamei/
  date: '2025-09-16'
  time: 12PM
  where: CSB 453
  description: >
    AI agents hold great value for enterprises but are notoriously difficult to productionize in a
    robust and reliable way. Enterprise agents must internalize task context, constraints, and
    success metrics to be reliable, yet learning directly in production is risky and often infeasible.
    Veris is a simulation-first experiential learning platform for training and evaluating
    domain-specific AI agents through simulated experience. I will present how Veris constructs
    high-fidelity interactive environments that mirror target deployments, including tool APIs, data
    schemas, user behaviors, and organizational policies. Then I will discuss how Veris supports
    multiple post-training paths like RL with online rollouts and trajectory replay, and iterative
    prompt or policy optimization. Finally, I will outline current challenges and research opportunities.  
  bio: > 
    Mehdi is the cofounder and CEO of Veris AI, an agentic infrastructure company based in NY,
    building simulation training grounds for enterprise AI agents. Veris is named on the Future50
    list by the Generalist and is backed by Decibel Ventures and ACrew Capital.    
    
    Mehdi is an applied AI researcher, builder, and industry leader. He holds a PhD in Electrical
    Engineering and Computer Science and an M.S. in Physics, both from UC Berkeley. Most recently,
    he served as the Director of AI at System.com


- title: 'MassGen: Multi-Agent Scaling System'
  tag: Seminar
  date: '2025-09-09'
  who: Chi Wang
  where: CSB 453
  time: 12PM
  wholink: https://www.linkedin.com/in/chi-wang-autogen/
  description: >
    Chi will present MassGen, a growing open-source multi-agent scaling system that tackles
    single-agent limitations through collaborative AI coordination. Built on AG2's research foundation,
    the system implements novel coordination of frontier AI agents. Early benchmarking across
    reasoning and instruction-following tasks shows statistically significant improvements, with
    growing industrial and academic adoption demonstrating the research opportunity for scaling
    intelligence through collaborative emergence.  
    
    Chi Wang is founder of AutoGen (now AG2), the open-source AgentOS to support agentic AI, and
    its parent open-source project FLAML, a fast library for AutoML & tuning. He has received
    multiple awards such as best paper of ICLR'24 LLM Agents Workshop and SIGKDD Data Science/Data
    Mining PhD Dissertation Award. He has 15+ years of research experience in Computer Science
    from Google DeepMind, Microsoft Research, Meta, UIUC and Tsinghua.

- title: Fall 2025 Agentic System Made Real Course
  tag: Course
  date: '2025-09-02'
  time: 10:10AM - 12:00PM T
  where: SCEP 415
  who: Junfeng Yang
  link: https://www.cs.columbia.edu/~junfeng/25fa-e6113/
  description: >
    This second iteration of the course will be led by [Junfeng Yang](https://www.cs.columbia.edu/~junfeng/),
    with a focus on exploring the emerging frontier of AI agents in the workplace through a
    hands-on, entrepreneurial lens. Check the Spring 2025 version
    [here](./events#250121-spring-2025-agentic-system-made-real-course).

- title: 'March 2025 Workshop: AI Agents for Work'
  tag: Workshop
  date: '2025-03-12'
  time: 10AM
  link: https://daplab.cs.columbia.edu/workshop/2025-03/
  description: >
    On March 12, 2025, DAPLab ran the first annual workshop at the Columbia Business
    School.  The one-day workshop to brought together over 200 industry leaders, Columbia
    faculty and students,  and technologists who are interested in the concept of
    AI agents.

    Speakers and panelists come from enterprises that are deploying agentic solutions,
    technologists  and infrastructure leaders, and researchers at leading AI labs
    as well as Columbia.  These include [Jason Wei](https://www.linkedin.com/in/jason-wei-5a7323b0/)
    from OpenAI who led  their chain-of-thought and agentic work, Danielle Perszyk
    from Amazon AGI, Jonathan Frankle  from Databricks, Deepak Dastrala from Intellect,
    [Cong Yu](https://www.linkedin.com/in/congyu)  who leads AI at Celonis, and more.

- title: 'Efficient Fine-Tuning and Compression of Large Language Models: Towards Low-bit and Ultra-Low Parameter Solutions'
  who: Jiajun Zhou
  date: '2025-07-07'
  time: 12PM
  description: >
    Efficient fine-tuning of Large Language Models (LLMs) is crucial due
    to their substantial memory and computational demands. This seminar discusses
    recent advancements in techniques aimed at  significantly reducing these costs,
    enabling effective adaptation of large-scale models even on resource-constrained
    hardware. The talk will begin with an overview of current challenges and mainstream
    approaches to compressing and fine-tuning LLMs, highlighting trade-offs between
    model size, accuracy, and efficiency. Subsequently, the speaker will introduce
    novel approaches  that enable fine-tuning at extremely low precision and ultra-low
    parameter regimes,  significantly reducing memory requirements without compromising
    performance. Finally, the  discussion will cover recent progress and future
    directions for achieving efficient deployment  of LLMs in real-world applications.  
    
    Jiajun Zhou is currently a Ph.D. student in the Department of Electrical
    and Electronic  Engineering at the University of Hong Kong (HKU), supervised
    by Prof. Ngai Wong, and a visiting  scholar at the University of California,
    Santa Barbara (UCSB). He received his Master's degree  in IC Design Engineering
    from the Hong Kong University of Science and Technology (HKUST) in 2019.  He
    previously worked as a Research Assistant at the Chinese University of Hong
    Kong (CUHK).  His research primarily focuses on developing innovative frameworks
    for efficient training and  inference of Large Language Models (LLMs), particularly
    through quantization, low-bit  optimization, and tensor decomposition. He has
    published extensively in AI and hardware  acceleration venues, including NAACL,
    IEEE FCCM, and IEEE TCAD.\n"

- title: 'Multi-Agent Systems in the Era of LLMs: Testbeds, Applications, and Beyond'
  who: Yusen Zhang
  date: '2025-07-10'
  time: 12PM
  description: >
    Autonomous agents powered by large language models (LLMs) are emerging
    as powerful tools for a  wide range of tasks. However, a single agent often
    faces performance ceilings, especially when  tackling complex workflows like
    running an AI company or AI4Research, and is inherently limited  in scenarios
    that involve multiple instances, such as simulations, embodied agents, and digital
    twins. In this talk, I will present Multi-Agent Large Language Models (MA-LLMs),
    a promising  paradigm designed to overcome the fundamental limitations of single-agent
    systems. I will begin  by highlighting three threads of my previous work that
    lay the groundwork for MA-LLMs. Next,  I'll introduce our research on fairness
    summarization, which demonstrates challenges that a  single agent struggles
    to handle well. Then, I will present how agents can collaborate in a  chain-of-agent
    manner to solve difficult tasks, such as long-document summarization and  multi-step
    reasoning. Finally, I will reflect on current limitations in MA-LLMs and outline
    my  long-term vision of building Agent Societies: a human-centric society consisting
    of scalable,  trustworthy, and collaborative intelligent agents and humans.  
    
    Yusen Zhang is a fourth-year CS PhD student at Penn State University, advised
    by Dr. Rui Zhang.  He has done industry research internships at Amazon, Microsoft,
    and Google. He also worked  closely with Dr. Dragomir Radev. He received his
    master's degree from Emory University,  advised by Dr. Jinho D. Choi.

- title: 'The Road to High-Quality LLM Inference Services: System, Data, and Context'
  who: Yizheng Jiao
  date: '2025-07-17'
  time: 12PM
  description: >
    This talk is about sharing the experience of building enterprise LLM inference
    services including

    1. high-level principles of increasing performance and saving costs
    2. a data selection algorithm to finetune LLM to increase the accuracy of domain-specific questions
    3. a method to enhance users' prompt with domain-specific knowledge bases.

    Yizheng Jiao graduated from UNC Chapel Hill with a doctoral degree in 2022. He
    joined Bytedance  after graduation and am doing research on LLM systems. His goal
    is to build efficient and  accurate LLM services with experience includes LLM
    inference systems, data selection for LLM  finetuning, and prompt optimization.

- title: From Serving LLMs to Serving Agents on the Cloud
  tag: Seminar
  date: '2025-07-24'
  time: 12PM
  who: Xiaozhe Yao
  description: >
    In this talk, I will discuss key challenges in building agentic AI systems in
    the cloud. I will highlight DeltaZip, our recent work on efficiently deploying
    multiple fine-tuned models -- a step we believe is essential toward enabling future
    AI systems. The core insight behind DeltaZip is that fine-tuning often introduces
    small-magnitude changes to a pre-trained model. By co-designing the serving system
    and compression algorithm, DeltaZip achieves a 2x to 12x throughput improvement
    over state-of-the-art systems. In addition to this project, I will share some
    ongoing challenges we are tackling in this space.

    Xiaozhe Yao is a third-year doctoral student at Systems Group, Department of Computer
    Science, ETH Zurich advised by Prof. Dr. Ana Klimović. His research explores the
    complex and fundamental tensions between three pillars: from optimizing systems
    for efficient ML, to improving data quality and organization for ML, to developing
    frameworks that bridge the gap between algorithms and their practical deployment.
    Through this multi-faceted approach, his work aims to better understand and build
    AI systems.

- title: Spring 2025 Agentic System Made Real Course
  tag: Course
  date: '2025-01-21'
  time: 10:10AM - 11:25AM TR
  who: Eugene Wu and Kostis Kaffes
  link: https://w6113.github.io/
  description: >
    LLMs have opened new possibilities of automated agents that plan and complete tasks on the
    user's behalf. Such agents have the potential to usher in a new industrial revolution by
    automating organizational processes. This graduate-level course will cut across the technology
    stack to examine the research questions that need to be answered for agents to be possible in
    real tasks that matter. Each session will review 1-3 papers or systems, and discuss research
    opportunities that arise from the gap between existing research and enterprise requirements.
    Topics will span systems (data systems and ML systems), AI (LLMs, agent-based planning), HCI,
    and theory (reinforcement learning, markets).
